# LLM νμΈνλ‹ λ° μ¬ν•™μµ ν”„λ΅μ νΈ

μ¤ν” μ†μ¤ LLM λ¨λΈμ νμΈνλ‹κ³Ό μ¬ν•™μµμ„ μ„ν• Python ν”„λ΅μ νΈμ…λ‹λ‹¤.

## μ£Όμ” κΈ°λ¥

- π€ **λ‹¤μ–‘ν• μ¤ν” μ†μ¤ LLM μ§€μ›**: Llama, Mistral, GPT-2, Gemma λ“± 50+ λ¨λΈ
- π― **ν¨μ¨μ μΈ νμΈνλ‹**: LoRA, QLoRAλ¥Ό ν™μ©ν• λ©”λ¨λ¦¬ ν¨μ¨μ  ν•™μµ
- π† **DPO κ°•ν™”ν•™μµ**: Direct Preference OptimizationμΌλ΅ RLHF λ€μ²΄
- π¨ **λ©€ν‹°λ¨λ‹¬ μ§€μ›**: LLaVA, BLIP-2 λ“± μ΄λ―Έμ§€-ν…μ¤νΈ λ¨λΈ νμΈνλ‹
- π“Ή **λ™μμƒ λ¶„μ„**: ffmpeg + Whisper + λ©€ν‹°λ¨λ‹¬ LLM ν†µν•© νμ΄ν”„λΌμΈ
- π **REST API μ„λ²„**: FastAPI κΈ°λ° ν”„λ΅λ•μ… λ λ”” API
- π“ **λ°μ΄ν„° μ „μ²λ¦¬**: μ»¤μ¤ν…€ λ°μ΄ν„°μ…‹ μ²λ¦¬ λ° ν¬λ§·ν…
- π”§ **μ μ—°ν• μ„¤μ •**: YAML κΈ°λ° μ„¤μ • κ΄€λ¦¬
- π“ **ν•™μµ λ¨λ‹ν„°λ§**: WandB, TensorBoard μ§€μ›

## ν”„λ΅μ νΈ κµ¬μ΅°

```
llm/
β”β”€β”€ configs/          # μ„¤μ • νμΌλ“¤
β”‚   β”β”€β”€ train_config.yaml  # SFT ν•™μµ μ„¤μ •
β”‚   β””β”€β”€ dpo_config.yaml    # DPO ν•™μµ μ„¤μ •
β”β”€β”€ data/             # ν•™μµ λ°μ΄ν„°
β”β”€β”€ models/           # μ €μ¥λ λ¨λΈ
β”β”€β”€ outputs/          # ν•™μµ κ²°κ³Ό λ° λ΅κ·Έ
β”β”€β”€ src/              # μ†μ¤ μ½”λ“
β”‚   β”β”€β”€ data_utils.py      # λ°μ΄ν„° μ²λ¦¬
β”‚   β”β”€β”€ dpo_utils.py       # DPO λ°μ΄ν„° μ²λ¦¬
β”‚   β”β”€β”€ model_utils.py     # λ¨λΈ λ΅λ”© λ° μ„¤μ •
β”‚   β”β”€β”€ train.py           # SFT ν•™μµ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ train_dpo.py       # DPO ν•™μµ μ¤ν¬λ¦½νΈ
β”‚   β””β”€β”€ inference.py       # μ¶”λ΅  μ¤ν¬λ¦½νΈ
β”β”€β”€ scripts/          # μ ν‹Έλ¦¬ν‹° μ¤ν¬λ¦½νΈ
β”β”€β”€ notebooks/        # Jupyter λ…ΈνΈλ¶
β”β”€β”€ requirements.txt  # μμ΅΄μ„± ν¨ν‚¤μ§€
β”β”€β”€ README.md         # ν”„λ΅μ νΈ λ¬Έμ„
β””β”€β”€ DPO_GUIDE.md      # DPO κ°€μ΄λ“
```

## μ„¤μΉ λ°©λ²•

1. κ°€μƒν™κ²½ μƒμ„± (κ¶μ¥)
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# λλ”
venv\Scripts\activate  # Windows
```

2. μμ΅΄μ„± μ„¤μΉ
```bash
pip install -r requirements.txt
```

## μ‚¬μ© λ°©λ²•

### 1. κΈ°λ³Έ νμΈνλ‹

```bash
python src/train.py \
    --model_name "meta-llama/Llama-2-7b-hf" \
    --dataset_path "data/train.json" \
    --output_dir "models/llama2-finetuned" \
    --num_epochs 3 \
    --batch_size 4
```

### 2. LoRAλ¥Ό μ‚¬μ©ν• ν¨μ¨μ  νμΈνλ‹

```bash
python src/train.py \
    --model_name "meta-llama/Llama-2-7b-hf" \
    --dataset_path "data/train.json" \
    --output_dir "models/llama2-lora" \
    --use_lora \
    --lora_r 16 \
    --lora_alpha 32 \
    --num_epochs 3
```

### 3. μ„¤μ • νμΌμ„ μ‚¬μ©ν• ν•™μµ

```bash
python src/train.py --config configs/train_config.yaml
```

### 4. DPO κ°•ν™”ν•™μµ (μ„ νƒμ‚¬ν•­)

```bash
python src/train_dpo.py \
    --model_name "models/llama2-finetuned" \
    --dataset_path "data/preference_train.json" \
    --output_dir "models/llama2-dpo" \
    --beta 0.1 \
    --num_epochs 1
```

### 5. μ¶”λ΅  μ‹¤ν–‰

```bash
python src/inference.py \
    --model_path "models/llama2-dpo" \
    --prompt "λ‹Ήμ‹ μ μ§λ¬Έμ„ μ…λ ¥ν•μ„Έμ”"
```

### 6. API μ„λ²„ μ‹¤ν–‰

```bash
# API μ„λ²„ μ‹μ‘
python src/api_server.py \
    --model_path "models/llama2-dpo" \
    --host 0.0.0.0 \
    --port 8000

# λλ” μ¤ν¬λ¦½νΈ μ‚¬μ©
./scripts/start_api.sh

# API λ¬Έμ„: http://localhost:8000/docs
```

API μ‚¬μ© μμ :
```bash
# cURLλ΅ μ”μ²­
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"instruction": "Pythonμ΄λ€?", "max_new_tokens": 200}'
```

## λ°μ΄ν„° ν¬λ§·

### SFT (Supervised Fine-Tuning) λ°μ΄ν„°

```json
[
    {
        "instruction": "μ§λ¬Έ λλ” μ§€μ‹μ‚¬ν•­",
        "input": "μ¶”κ°€ μ…λ ¥ (μ„ νƒμ‚¬ν•­)",
        "output": "κΈ°λ€λλ” μ¶λ ¥"
    }
]
```

### DPO (μ„ νΈλ„) λ°μ΄ν„°

```json
[
    {
        "prompt": "μ§λ¬Έ λλ” ν”„λ΅¬ν”„νΈ",
        "chosen": "λ” μΆ‹μ€ μ‘λ‹µ",
        "rejected": "λ μΆ‹μ€ μ‘λ‹µ"
    }
]
```

μμ„Έν• λ‚΄μ©μ€ `DPO_GUIDE.md`λ¥Ό μ°Έμ΅°ν•μ„Έμ”.

## μ„¤μ • μµμ…

μ£Όμ” μ„¤μ • νλΌλ―Έν„°:

- `model_name`: μ‚¬μ©ν•  λ¨λΈ μ΄λ¦„ (Hugging Face model ID)
- `dataset_path`: ν•™μµ λ°μ΄ν„° κ²½λ΅
- `output_dir`: λ¨λΈ μ €μ¥ λ””λ ‰ν† λ¦¬
- `num_epochs`: ν•™μµ μ—ν¬ν¬ μ
- `batch_size`: λ°°μΉ ν¬κΈ°
- `learning_rate`: ν•™μµλ¥ 
- `use_lora`: LoRA μ‚¬μ© μ—¬λ¶€
- `quantization`: μ–‘μν™” μµμ… (4bit, 8bit)

μμ„Έν• μ„¤μ •μ€ `configs/train_config.yaml`μ„ μ°Έμ΅°ν•μ„Έμ”.

## μ§€μ› λ¨λΈ

- Llama 2/3 (Meta)
- Mistral (Mistral AI)
- Falcon (TII)
- GPT-2 (OpenAI)
- BLOOM (BigScience)
- κΈ°νƒ€ Hugging Face Transformers νΈν™ λ¨λΈ

## ν•™μµ λ¨λ‹ν„°λ§

### WandB μ‚¬μ©
```bash
export WANDB_PROJECT="llm-finetuning"
python src/train.py --config configs/train_config.yaml
```

### TensorBoard μ‚¬μ©
```bash
tensorboard --logdir outputs/logs
```

## λ©”λ¨λ¦¬ μµμ ν™” ν

1. **LoRA μ‚¬μ©**: μ „μ²΄ νμΈνλ‹ λ€λΉ„ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν¬κ² κ°μ†
2. **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: `gradient_checkpointing=True` μ„¤μ •
3. **4bit μ–‘μν™”**: `quantization=4bit` μ„¤μ •
4. **λ°°μΉ ν¬κΈ° μ΅°μ •**: GPU λ©”λ¨λ¦¬μ— λ§κ² μ΅°μ •
5. **κ·Έλλ””μ–ΈνΈ λ„μ **: `gradient_accumulation_steps` μ‚¬μ©

## λΌμ΄μ„ μ¤

MIT License

## κΈ°μ—¬

μ΄μμ™€ ν’€ λ¦¬ν€μ¤νΈλ¥Ό ν™μν•©λ‹λ‹¤!

