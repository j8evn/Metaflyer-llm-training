# ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¹ ë¥¸ ì‹œì‘

ì´ë¯¸ì§€ë¥¼ ì´ìš©í•œ LLM íŒŒì¸íŠœë‹ì„ 5ë‹¨ê³„ë¡œ ì‹œì‘í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì´ë€?

ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì´í•´í•˜ëŠ” AI ëª¨ë¸ì…ë‹ˆë‹¤:
- ğŸ“¸ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì„¤ëª… ìƒì„±
- â“ ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€
- ğŸ” ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„

## ğŸš€ 5ë‹¨ê³„ë¡œ ì‹œì‘í•˜ê¸°

### 1ë‹¨ê³„: ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (2ë¶„)

```bash
# ë©€í‹°ëª¨ë‹¬ìš© ì¶”ê°€ íŒ¨í‚¤ì§€
pip install -r requirements_multimodal.txt
```

### 2ë‹¨ê³„: ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„ (5ë¶„)

```bash
# ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/images

# ì´ë¯¸ì§€ íŒŒì¼ì„ data/images/ ì— ë³µì‚¬
# ì˜ˆ: cat.jpg, dog.jpg, food.jpg ë“±
```

ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ:
- Unsplash: https://unsplash.com/
- Pexels: https://www.pexels.com/

### 3ë‹¨ê³„: JSON ë©”íƒ€ë°ì´í„° ìƒì„± (3ë¶„)

```json
// data/multimodal_train.json
[
    {
        "image": "data/images/cat.jpg",
        "question": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?",
        "answer": "ê³ ì–‘ì´ê°€ ì†ŒíŒŒì— ì•‰ì•„ ìˆìŠµë‹ˆë‹¤."
    },
    {
        "image": "data/images/dog.jpg",
        "text": "ê³¨ë“  ë¦¬íŠ¸ë¦¬ë²„ ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë†€ê³  ìˆìŠµë‹ˆë‹¤."
    }
]
```

ë˜ëŠ” ì œê³µëœ ìƒ˜í”Œ ì‚¬ìš©:
```bash
# ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŒ
cat data/multimodal_train.json
```

### 4ë‹¨ê³„: í•™ìŠµ ì‹¤í–‰ (1-3ì‹œê°„)

```bash
python src/train_multimodal.py \
    --model_name "llava-hf/llava-1.5-7b-hf" \
    --dataset_path "data/multimodal_train.json" \
    --output_dir "outputs/llava_custom"
```

ë˜ëŠ” ì„¤ì • íŒŒì¼ ì‚¬ìš©:
```bash
python src/train_multimodal.py --config configs/multimodal_config.yaml
```

### 5ë‹¨ê³„: ì¶”ë¡  í…ŒìŠ¤íŠ¸ (1ë¶„)

```bash
# ì´ë¯¸ì§€ ì„¤ëª…
python src/inference_multimodal.py \
    --model_path "outputs/llava_custom/final_model" \
    --model_type "llava" \
    --image "test_image.jpg"

# ì´ë¯¸ì§€ Q&A
python src/inference_multimodal.py \
    --model_path "outputs/llava_custom/final_model" \
    --model_type "llava" \
    --image "test_image.jpg" \
    --question "ì´ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì„ ë³¼ ìˆ˜ ìˆë‚˜ìš”?"

# ëŒ€í™”í˜• ëª¨ë“œ
python src/inference_multimodal.py \
    --model_path "outputs/llava_custom/final_model" \
    --model_type "llava"
```

---

## ğŸ“Š ì§€ì› ëª¨ë¸

### LLaVA (ê¶Œì¥) â­â­â­â­â­

```bash
# LLaVA 1.5 7B
--model_name "llava-hf/llava-1.5-7b-hf"

# LLaVA 1.5 13B (ë” ê°•ë ¥)
--model_name "llava-hf/llava-1.5-13b-hf"
```

**ì¥ì :** GPT-4Vì™€ ìœ ì‚¬í•œ ì„±ëŠ¥, ì˜¤í”ˆ ì†ŒìŠ¤

### BLIP-2

```bash
# BLIP-2 OPT 2.7B (ê°€ë²¼ì›€)
--model_name "Salesforce/blip2-opt-2.7b" --model_type "blip2"
```

**ì¥ì :** ì ì€ ë©”ëª¨ë¦¬, ë¹ ë¥¸ í•™ìŠµ

---

## ğŸ’¡ ì‹¤ì „ ì˜ˆì œ

### ì˜ë£Œ ì˜ìƒ ë¶„ì„

```json
// data/medical_images.json
[
    {
        "image": "data/images/xray_chest.jpg",
        "question": "ì´ X-rayì—ì„œ ì´ìƒ ì†Œê²¬ì´ ìˆë‚˜ìš”?",
        "answer": "ì •ìƒ í‰ë¶€ X-rayì…ë‹ˆë‹¤. íì™€ ì‹¬ì¥ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìœ¼ë©° íŠ¹ì´ ì†Œê²¬ì€ ê´€ì°°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    }
]
```

í•™ìŠµ:
```bash
python src/train_multimodal.py \
    --model_name "llava-hf/llava-1.5-7b-hf" \
    --dataset_path "data/medical_images.json" \
    --output_dir "outputs/medical_vision_assistant"
```

### ì œí’ˆ ì„¤ëª… ìƒì„±

```json
// data/product_images.json
[
    {
        "image": "data/images/product_001.jpg",
        "instruction": "ì´ ì œí’ˆì˜ ë§¤ë ¥ì ì¸ íŒë§¤ ë¬¸êµ¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”",
        "output": "í”„ë¦¬ë¯¸ì—„ ê°€ì£½ ì§€ê°‘ - ì¥ì¸ ì •ì‹ ì´ ë‹´ê¸´ ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ë””ìì¸. ì‹¤ìš©ì„±ê³¼ ìŠ¤íƒ€ì¼ì„ ë™ì‹œì— ì¶©ì¡±ì‹œí‚¤ëŠ” ì™„ë²½í•œ ì„ íƒì…ë‹ˆë‹¤."
    }
]
```

### ì°¨íŠ¸ ë¶„ì„

```json
// data/chart_images.json
[
    {
        "image": "data/images/sales_chart.jpg",
        "question": "ì´ íŒë§¤ ê·¸ë˜í”„ì˜ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•˜ì„¸ìš”",
        "answer": "2023ë…„ ì´ˆë°˜ë¶€í„° íŒë§¤ëŸ‰ì´ ê¾¸ì¤€íˆ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤. íŠ¹íˆ 3ì›”ê³¼ 6ì›”ì— ê¸‰ê²©í•œ ìƒìŠ¹ì´ ìˆì—ˆìœ¼ë©°, ì „ë…„ ëŒ€ë¹„ í‰ê·  25% ì¦ê°€í–ˆìŠµë‹ˆë‹¤."
    }
]
```

---

## âš¡ ë©”ëª¨ë¦¬ ìµœì í™”

ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤!

### GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ

```yaml
# configs/multimodal_config.yaml

# 1. LoRA ì‚¬ìš© (í•„ìˆ˜)
lora:
  use_lora: true
  r: 16

# 2. ì‘ì€ ë°°ì¹˜
training:
  batch_size: 1
  gradient_accumulation_steps: 16

# 3. ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
advanced:
  gradient_checkpointing: true

# 4. ì–‘ìí™”
quantization:
  use_quantization: true
  bits: 4
```

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

| ëª¨ë¸ | ìµœì†Œ GPU (LoRA) | ê¶Œì¥ GPU |
|------|-----------------|----------|
| BLIP-2 2.7B | 8GB | 12GB |
| LLaVA 1.5 7B | 16GB | 24GB |
| LLaVA 1.5 13B | 24GB | 40GB |

---

## ğŸ¯ ì „ì²´ ì›Œí¬í”Œë¡œìš°

```bash
# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
pip install -r requirements_multimodal.txt

# 2. ë°ì´í„° ì¤€ë¹„
mkdir -p data/images
# ì´ë¯¸ì§€ ë³µì‚¬
cp ~/Pictures/*.jpg data/images/

# 3. ë©”íƒ€ë°ì´í„° ìƒì„±
# data/multimodal_train.json í¸ì§‘

# 4. í•™ìŠµ
python src/train_multimodal.py --config configs/multimodal_config.yaml

# 5. ì¶”ë¡ 
python src/inference_multimodal.py \
    --model_path "outputs/multimodal_checkpoints/final_model" \
    --image "test.jpg"
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- **MULTIMODAL_GUIDE.md** - ì™„ì „í•œ ê°€ì´ë“œ
- **examples/multimodal_example.py** - Python ì˜ˆì œ
- **configs/multimodal_config.yaml** - ì„¤ì • íŒŒì¼

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. âœ… ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì§‘
2. âœ… JSON ë©”íƒ€ë°ì´í„° ìƒì„±
3. âœ… í•™ìŠµ ì‹¤í–‰
4. âœ… ì„±ëŠ¥ í‰ê°€
5. âœ… API ì„œë²„ í†µí•©

**ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì´í•´í•˜ëŠ” AIë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!** ğŸ¨ğŸ¤–


